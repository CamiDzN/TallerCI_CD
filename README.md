# ğŸ“˜ Taller CI/CD y GitOps con MLOps en Kubernetes

## ğŸ¯ DescripciÃ³n del Proyecto
Este proyecto implementa un flujo de **despliegue continuo (CI/CD)** con enfoque **GitOps** para una API de inferencia desarrollada en FastAPI, desplegada en un clÃºster de **Kubernetes (MicroK8s)**. El sistema incluye **monitoreo con Prometheus y Grafana**, pruebas de carga con Locust y automatizaciÃ³n del despliegue con **Argo CD**. Todo el flujo estÃ¡ integrado con GitHub Actions para construir imÃ¡genes Docker y actualizar automÃ¡ticamente el entorno productivo.
## ğŸ§± Componentes Principales

| Componente         | FunciÃ³n                                                    |
|--------------------|------------------------------------------------------------|
| **FastAPI**        | API de inferencia con modelo ML (Random Forest)            |
| **Locust**         | Pruebas de carga sobre el endpoint `/predict`              |
| **Prometheus**     | RecolecciÃ³n de mÃ©tricas de la API                          |
| **Grafana**        | VisualizaciÃ³n de mÃ©tricas desde Prometheus                 |
| **Argo CD**        | Despliegue automÃ¡tico desde GitHub (GitOps)                |
| **DockerHub**      | Repositorio de imÃ¡genes para API y Locust                  |
| **GitHub Actions** | Entrenamiento del modelo, construcciÃ³n y push de imÃ¡genes  |

---
## ğŸ“ Estructura del Proyecto
```
TallerCI_CD/
â”œâ”€â”€ API/
â”‚ â”œâ”€â”€ app/
â”‚ â”‚ â””â”€â”€ main.py
â”‚ â”œâ”€â”€ train_model.py
â”‚ â”œâ”€â”€ Dockerfile
â”‚ â””â”€â”€ requirements.txt
â”œâ”€â”€ locust/
â”‚ â””â”€â”€ locustfile.py
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ manifests/
â”‚ â”œâ”€â”€ fastapi-deployment.yaml
â”‚ â”œâ”€â”€ fastapi-service.yaml
â”‚ â”œâ”€â”€ locust-k8s.yaml
â”‚ â”œâ”€â”€ prometheus-configmap.yaml
â”‚ â”œâ”€â”€ prometheus-deployment.yaml
â”‚ â”œâ”€â”€ prometheus-service.yaml
â”‚ â”œâ”€â”€ grafana-datasources.yaml
â”‚ â”œâ”€â”€ grafana-deployment.yaml
â”‚ â”œâ”€â”€ grafana-service.yaml
â”‚ â”œâ”€â”€ namespace-observability.yaml
â”‚ â””â”€â”€ kustomization.yaml
â”œâ”€â”€ argo-cd/
â”‚ â”œâ”€â”€ app.yaml
â”‚ â””â”€â”€ install.yaml
â””â”€â”€ .github/
â””â”€â”€ workflows/
â””â”€â”€ ci-cd.yml
```
---

## ğŸš€ Despliegue Paso a Paso

### 1. Habilitar complementos en MicroK8s

```bash
microk8s enable dns registry ingress
```
### 2. Instalar Argo CD desde archivo local

En lugar de instalar desde la URL remota, este proyecto incluye el manifiesto completo de instalaciÃ³n de Argo CD en la carpeta argo-cd/install.yaml. Para instalarlo:

```bash
microk8s kubectl create namespace argocd
microk8s kubectl apply -n argocd -f argo-cd/install.yaml
```
El manifiesto fue descargado desde:
```bash
https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml
```
### 3. Obtener contraseÃ±a de acceso

```bash
microk8s kubectl -n argocd get secret argocd-initial-admin-secret \
  -o jsonpath="{.data.password}" | base64 -d && echo
```

### 4 . Obtener contraseÃ±a de acceso

```bash
microk8s kubectl -n argocd get secret argocd-initial-admin-secret \
  -o jsonpath="{.data.password}" | base64 -d && echo
```
### 4 . Obtener contraseÃ±a de acceso

```bash
microk8s kubectl apply -f argo-cd/app.yaml -n argocd
```
## Servicios desplegados (puertos locales)

| Servicio   | URL local                                                  | Puerto  |
| ---------- | ---------------------------------------------------------- | ------- |
| FastAPI    | [http://localhost:30080/docs](http://localhost:30080/docs) | `30080` |
| Prometheus | [http://localhost:30090](http://localhost:30090)           | `30090` |
| Grafana    | [http://localhost:30030](http://localhost:30030)           | `30030` |
| Locust UI  | [http://localhost:30009](http://localhost:30009)           | `30009` |
| Argo CD    | [http://localhost:8080](http://localhost:8080)             | `8080`  |

## ğŸ“Š Observabilidad

**Prometheus** recolecta mÃ©tricas desde el endpoint `/metrics` expuesto por FastAPI.

**Grafana** visualiza mÃ©tricas clave del modelo, tales como:

- `inference_requests_total` â€“ Total de solicitudes de inferencia recibidas.
- `inference_request_latency_seconds` â€“ Histograma de latencia de las inferencias en segundos.

Estas mÃ©tricas estÃ¡n habilitadas gracias a la librerÃ­a `prometheus_client` y estÃ¡n configuradas en Kubernetes mediante el archivo:

```yaml
manifests/grafana-datasources.yaml
